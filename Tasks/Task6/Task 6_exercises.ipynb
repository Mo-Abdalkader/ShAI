{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uua1wvw7iQB4"
   },
   "source": [
    "![](logo1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m ______  ___     ______                        _________\n",
      "___   |/  /________  /_______ _______ ______________  /\n",
      "__  /|_/ /_  __ \\_  __ \\  __ `/_  __ `__ \\  _ \\  __  / \n",
      "_  /  / / / /_/ /  / / / /_/ /_  / / / / /  __/ /_/ /  \n",
      "/_/  /_/  \\____//_/ /_/\\__,_/ /_/ /_/ /_/\\___/\\__,_/   \n",
      "                                                       \n",
      "_____________ _________      ___________        _________            \n",
      "___    |__  /_______  /_____ ___  /__  /_______ ______  /____________\n",
      "__  /| |_  __ \\  __  /_  __ `/_  /__  //_/  __ `/  __  /_  _ \\_  ___/\n",
      "_  ___ |  /_/ / /_/ / / /_/ /_  / _  ,<  / /_/ // /_/ / /  __/  /    \n",
      "/_/  |_/_.___/\\__,_/  \\__,_/ /_/  /_/|_| \\__,_/ \\__,_/  \\___//_/     \n",
      "                                                                     \n",
      " \u001b[0m\n",
      "\u001b[94m                                                                        \n",
      "                                                                       \n",
      "_______________________________________________________________________\n",
      "_/_____//_____//_____//_____//_____//_____//_____//_____//_____//_____/\n",
      "                                                                       \n",
      "                                                                       \n",
      " \u001b[0m\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMnWC3LuifEi"
   },
   "source": [
    "# **shAI Training 2023 | Level 1**\n",
    "\n",
    "## Task #8 (End-to-End ML Project {part_2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rbe_ZnKi-uY"
   },
   "source": [
    "## Welcome to the exercises for reviewing second part of end to end ML project.\n",
    "**Make sure that you read and understand ch2 from the hands-on ML book (page 72 to the end of the chapter ) before start with this notebook.**\n",
    "\n",
    "**If you stuck with anything reread that part from the book and feel free to ask about anything in the messenger group as you go along.**\n",
    "\n",
    " ## Good Luck : )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zAbRZ0fwfOb4"
   },
   "source": [
    "## first run the following cell for the first part of the project to continue your work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Q3v160SJfL7U"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ObbhNRgSfu6_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    os.makedirs(housing_path, exist_ok=True)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "    \n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "   csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "   return pd.read_csv(csv_path)\n",
    "   \n",
    "fetch_housing_data()\n",
    "housing = load_housing_data()\n",
    "\n",
    "rooms_ix, bedrooms_ix, population_ix, household_ix = [\n",
    "    list(housing.columns).index(col)\n",
    "    for col in (\"total_rooms\", \"total_bedrooms\", \"population\", \"households\")]\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True):\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, household_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household,\n",
    "                         bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "        \n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n",
    "housing = train_set.drop(\"median_house_value\", axis=1)\n",
    "housing_labels = train_set[\"median_house_value\"].copy()\n",
    "\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    " ('imputer', SimpleImputer(strategy=\"median\")),\n",
    " ('attribs_adder', CombinedAttributesAdder()),\n",
    " ('std_scaler', StandardScaler())])\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    " (\"num\", num_pipeline, num_attribs),\n",
    " (\"cat\", OneHotEncoder(), cat_attribs)])\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(housing_prepared, housing_labels, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wa6vPfm6jxsF"
   },
   "source": [
    "# 1- Select and Train a Model\n",
    "\n",
    "# Let’s first train a LinearRegression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JCl0ZYDRjGz_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE HERE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nDxOY7GmTNc"
   },
   "source": [
    "# First try it out on a few instances from the training set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7Lx7VQm7pwSQ"
   },
   "outputs": [],
   "source": [
    "some_data = X_test[:5]\n",
    "some_labels = y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BU-ynaaIpYHO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction = 137958 | Actual value = 96700 \n",
      "Model prediction = 131237 | Actual value = 75500 \n",
      "Model prediction = 303020 | Actual value = 430900 \n",
      "Model prediction = 224187 | Actual value = 332600 \n",
      "Model prediction = 348398 | Actual value = 500001 \n"
     ]
    }
   ],
   "source": [
    "# CODE HERE\n",
    "\n",
    "predictions = lin_reg.predict(some_data)\n",
    "\n",
    "for output, prediction in zip(some_labels, predictions):\n",
    "    print(f\"Model prediction = {str(round(prediction))} | Actual value = {str(round(output))} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjmwxoU-qFnb"
   },
   "source": [
    "# measure this regression model’s RMSE on the whole training set \n",
    "* sing Scikit-Learn’s mean_squared_error() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rczx22dFqRMc"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "aCYZh9ExqWMJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67617.33196607907\n"
     ]
    }
   ],
   "source": [
    "# CODE HERE\n",
    "\n",
    "housing_predictions = lin_reg.predict(X_train)\n",
    "lin_mse = mean_squared_error(y_train, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(lin_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLsKfuQpcfyx"
   },
   "source": [
    "# judge on the RMSE result for this model \n",
    "write down your answar "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnBVcR-MeFqa"
   },
   "source": [
    "A high RMSE suggests that the model's predictions are far from the actual values on average, indicating poor performance.\n",
    "\n",
    "I think it can be optimized a little bit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vImNak3CqqFo"
   },
   "source": [
    "# Let’s train a Decision Tree Regressor model \n",
    "## more powerful model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8syfCBveqY2q"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vrUPZzBhq-do"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE HERE\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state = 42)\n",
    "tree_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRhxYj0Aq9op"
   },
   "source": [
    "# Now evaluate the model on the training set \n",
    "* using Scikit-Learn’s mean_squared_error() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "DYCxUSCkrNIY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# CODE HERE\n",
    "\n",
    "housing_predictions2 = tree_reg.predict(X_train)\n",
    "lin_mse2 = mean_squared_error(y_train, housing_predictions2)\n",
    "lin_rmse2 = np.sqrt(lin_mse2)\n",
    "print(lin_rmse2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSxXI9b8iZPs"
   },
   "source": [
    "# Explaine this result \n",
    "write down your answar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVSMQ7kbiZSi"
   },
   "source": [
    "Overfitting!!\n",
    "\n",
    "Overfitting: Decision trees, especially if they're deep, have a tendency to overfit the training data. This means the model captures the noise in the training data rather than the underlying pattern. Consequently, it can perfectly predict the training data but perform poorly on unseen data. The RMSE being 0 indicates perfect predictions on the training set, but it might not generalize well to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71517.32474346654\n"
     ]
    }
   ],
   "source": [
    "# If i tried to test the model on a data that the model never seen before, The RMSE will differ like that\n",
    "\n",
    "housing_predictions3 = tree_reg.predict(X_test)\n",
    "lin_mse3 = mean_squared_error(y_test, housing_predictions3)\n",
    "lin_rmse3 = np.sqrt(lin_mse3)\n",
    "print(lin_rmse3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rj7b4zSPrdyH"
   },
   "source": [
    "# Evaluation Using Cross-Validation\n",
    "\n",
    "1-split the training set into 10 distinct subsets then train and evaluate the Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "JmNrgsBrwIe3"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "yXNPsWjcwMd_"
   },
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "\n",
    "tree_model = DecisionTreeRegressor()\n",
    "\n",
    "tree_scores = cross_val_score(tree_model, X_train, y_train, scoring='neg_mean_squared_error', cv=10)\n",
    "tree_rmse_scores = np.sqrt(np.abs(tree_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KqReIY3urLP8"
   },
   "source": [
    "2- display the resultant scores and calculate its Mean and Standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "1g8jIq-6raVF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree RMSE scores:\n",
      "1  : 71412.32\n",
      "2  : 70377.2\n",
      "3  : 78563.2\n",
      "4  : 70883.39\n",
      "5  : 65604.47\n",
      "6  : 80048.32\n",
      "7  : 70138.44\n",
      "8  : 69701.6\n",
      "9  : 68034.96\n",
      "10  : 68123.68\n",
      "\n",
      "RMSE Mean : 71288.76\n",
      "RMSE Std  : 4329.16\n"
     ]
    }
   ],
   "source": [
    "# CODE HERE\n",
    "\n",
    "print(\"Decision Tree RMSE scores:\")\n",
    "for index, score in enumerate(tree_rmse_scores, 1):\n",
    "    print(index, f\" : {round(score, 2)}\")\n",
    "\n",
    "print(\"\\nRMSE Mean :\", round(tree_rmse_scores.mean(), 2))\n",
    "\n",
    "print(\"RMSE Std  :\", round(tree_rmse_scores.std(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6paGk_hsGGY"
   },
   "source": [
    "3-repaet the same steps to compute the same scores for the Linear Regression  model \n",
    "\n",
    "*notice the difference between the results of the two models*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ol3C6DmusWfx"
   },
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "linear_scores = cross_val_score(linear_model, X_train, y_train, scoring='neg_mean_squared_error', cv=10)\n",
    "linear_rmse_scores = np.sqrt(np.abs(linear_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE scores:\n",
      "1  : 68197.29\n",
      "2  : 249437.33\n",
      "3  : 66920.17\n",
      "4  : 66377.69\n",
      "5  : 63339.96\n",
      "6  : 71755.04\n",
      "7  : 65900.12\n",
      "8  : 74877.21\n",
      "9  : 66411.72\n",
      "10  : 66863.08\n",
      "\n",
      "RMSE Mean : 86007.96\n",
      "RMSE Std  : 54563.55\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Regression RMSE scores:\")\n",
    "for index, score in enumerate(linear_rmse_scores, 1):\n",
    "    print(index, f\" : {round(score, 2)}\")\n",
    "\n",
    "print(\"\\nRMSE Mean :\", round(linear_rmse_scores.mean(), 2))\n",
    "\n",
    "print(\"RMSE Std  :\", round(linear_rmse_scores.std(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdQ85uTEtDy1"
   },
   "source": [
    "## Let’s train one last model the RandomForestRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "O1PPFq5TtdDP"
   },
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_model = RandomForestRegressor()\n",
    "forest_scores = cross_val_score(forest_model, X_train, y_train, scoring = \"neg_mean_squared_error\", cv = 10)\n",
    "forest_rmse_scores = np.sqrt(np.abs(forest_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gSxaBthCtw93"
   },
   "source": [
    "# repeat the same steps to compute the same scores its Mean and Standard deviation for the Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "AAc2MOQwt2lC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE scores:\n",
      "1  : 50338.55\n",
      "2  : 51811.25\n",
      "3  : 50662.83\n",
      "4  : 51926.09\n",
      "5  : 46460.65\n",
      "6  : 55167.45\n",
      "7  : 50232.74\n",
      "8  : 51008.23\n",
      "9  : 50215.77\n",
      "10  : 49813.02\n",
      "\n",
      "RMSE Mean : 50763.66\n",
      "RMSE Std  : 2051.69\n"
     ]
    }
   ],
   "source": [
    "# CODE HERE\n",
    "\n",
    "print(\"Random Forest RMSE scores:\")\n",
    "for index, score in enumerate(forest_rmse_scores, 1):\n",
    "    print(index, f\" : {round(score, 2)}\")\n",
    "\n",
    "print(\"\\nRMSE Mean :\", round(forest_rmse_scores.mean(), 2))\n",
    "\n",
    "print(\"RMSE Std  :\", round(forest_rmse_scores.std(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vn2u9DOxvE5S"
   },
   "source": [
    "# Save every model you experiment with \n",
    "*using the joblib library*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "mWyIi3mtva85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RandomForest_model.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE HERE\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(linear_model, 'LinearRegression_model.pkl')\n",
    "joblib.dump(tree_model,   'DecisionTree_model.pkl')\n",
    "joblib.dump(forest_model, 'RandomForest_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIC6O-h0wOBJ"
   },
   "source": [
    "## Now you have a shortlist of promising models. You now need to fine-tune them!\n",
    "# Fine-Tune Your Model\n",
    "\n",
    "## 1- Grid Search\n",
    "## evaluate all the possible combinations of hyperparameter values for the RandomForestRegressor \n",
    "*It may take a long time*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Y8Wqd-Pix3Sm"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "j-zNvGLhyGGb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=42),\n",
       "             param_grid=[{'max_features': [4, 5, 6, 7, 8],\n",
       "                          'n_estimators': [3, 5, 10, 20, 30]},\n",
       "                         {'bootstrap': [False], 'max_features': [2, 3, 4],\n",
       "                          'n_estimators': [3, 10]}],\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE HERE\n",
    "\n",
    "param_grid = [\n",
    "              {'n_estimators': [3, 5, 10, 20, 30], 'max_features':[4, 5, 6, 7, 8]},\n",
    "              {'bootstrap':[False], 'max_features':[2, 3, 4],'n_estimators':[3, 10]}\n",
    "]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state = 42)\n",
    "\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv = 5, scoring = 'neg_mean_squared_error', return_train_score = True)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EhYbsAnE0j75"
   },
   "source": [
    "with the evaluation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "qhDCrx0Y0ocN",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61025.88 {'max_features': 4, 'n_estimators': 3}\n",
      "56388.55 {'max_features': 4, 'n_estimators': 5}\n",
      "52948.7 {'max_features': 4, 'n_estimators': 10}\n",
      "51348.75 {'max_features': 4, 'n_estimators': 20}\n",
      "51052.07 {'max_features': 4, 'n_estimators': 30}\n",
      "59953.22 {'max_features': 5, 'n_estimators': 3}\n",
      "56379.74 {'max_features': 5, 'n_estimators': 5}\n",
      "53666.31 {'max_features': 5, 'n_estimators': 10}\n",
      "51786.05 {'max_features': 5, 'n_estimators': 20}\n",
      "51264.24 {'max_features': 5, 'n_estimators': 30}\n",
      "58607.04 {'max_features': 6, 'n_estimators': 3}\n",
      "54997.14 {'max_features': 6, 'n_estimators': 5}\n",
      "52162.56 {'max_features': 6, 'n_estimators': 10}\n",
      "50848.42 {'max_features': 6, 'n_estimators': 20}\n",
      "50600.31 {'max_features': 6, 'n_estimators': 30}\n",
      "59396.93 {'max_features': 7, 'n_estimators': 3}\n",
      "55799.64 {'max_features': 7, 'n_estimators': 5}\n",
      "53043.29 {'max_features': 7, 'n_estimators': 10}\n",
      "51032.06 {'max_features': 7, 'n_estimators': 20}\n",
      "50735.29 {'max_features': 7, 'n_estimators': 30}\n",
      "59048.57 {'max_features': 8, 'n_estimators': 3}\n",
      "55361.59 {'max_features': 8, 'n_estimators': 5}\n",
      "52514.46 {'max_features': 8, 'n_estimators': 10}\n",
      "50776.43 {'max_features': 8, 'n_estimators': 20}\n",
      "50533.19 {'max_features': 8, 'n_estimators': 30}\n",
      "63242.12 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "54728.03 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "60433.66 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "53471.02 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "57967.24 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "51579.79 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "# CODE HERE\n",
    "\n",
    "cvres = grid_search.cv_results_\n",
    "\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"],cvres[\"params\"]):\n",
    "    print(round(np.sqrt(np.abs(mean_score)), 2), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjRCrlqEyH1A"
   },
   "source": [
    "# Analyze the Best Models and Their Errors\n",
    "1-indicate the relative importance of each attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "y2MkCD1Byh9F"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.66276481e-02, 6.07537030e-02, 4.03096731e-02, 1.52423600e-02,\n",
       "       1.47674103e-02, 1.46739077e-02, 1.37022307e-02, 3.78997134e-01,\n",
       "       5.09914428e-02, 1.09765729e-01, 5.55973364e-02, 6.72479550e-03,\n",
       "       1.66078781e-01, 2.32494481e-04, 2.18657403e-03, 3.34878064e-03])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE HERE\n",
    "\n",
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances\n",
    "\n",
    "\n",
    "# array([6.84493392e-02, 6.49131340e-02, 4.17428333e-02, 1.45158216e-02,\n",
    "#        1.37060650e-02, 1.43001651e-02, 1.29591331e-02, 3.71833888e-01,\n",
    "#        4.94502910e-02, 1.09758357e-01, 6.11769498e-02, 7.39554036e-03,\n",
    "#        1.65012599e-01, 2.28668090e-04, 1.83994495e-03, 2.71727020e-03])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b01L7mUm1xTV"
   },
   "source": [
    "2-display these importance scores next to their corresponding attribute names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "dau43zXt14i7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.3789971339914692, 'median_income'),\n",
       " (0.16607878076062677, '<1H OCEAN'),\n",
       " (0.1097657285841296, 'population_per_household'),\n",
       " (0.06662764807490762, 'longitude'),\n",
       " (0.060753703027052984, 'latitude'),\n",
       " (0.055597336394445, 'bedroom_per_room'),\n",
       " (0.050991442767811965, 'ocean_proximity'),\n",
       " (0.04030967310602871, 'housing_median_age'),\n",
       " (0.01524235997423226, 'total_rooms'),\n",
       " (0.014767410308921418, 'total_bedrooms'),\n",
       " (0.014673907701135872, 'population'),\n",
       " (0.013702230656568464, 'households'),\n",
       " (0.0067247955017928065, 'rooms_per_household'),\n",
       " (0.00334878064431095, 'NEAR BAY'),\n",
       " (0.0021865740252877777, 'ISLAND'),\n",
       " (0.0002324944812786841, 'INLAND')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE HERE\n",
    "\n",
    "num_attribs = list(train_set.drop([\"median_house_value\"],axis = 1).columns)\n",
    "extra_attribs = [\"population_per_household\", \"bedroom_per_room\", \"rooms_per_household\"]\n",
    "cat_one_hot_attribs = ['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN']\n",
    "attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
    "sorted(zip(feature_importances, attributes), reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esOPiD6Pyice"
   },
   "source": [
    "## Now is the time to evaluate the final model on the test set.\n",
    "# Evaluate Your System on the Test Set\n",
    "\n",
    "- Get the predictors and the labels from your test set\n",
    "- Run your full_pipeline to transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "VBfW1WG823TE"
   },
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "\n",
    "# The test set was generated after transforming the whole dataset so this so this point is already done at CODE CELL num 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNVnMSJy28xt"
   },
   "source": [
    "- Evaluate the final model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "HrcgAUoy2_tc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49611.310138215784"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE HERE\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_predictions = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, best_predictions)\n",
    "rmse = np.sqrt(np.abs(mse))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYBxgnsx3Ipr"
   },
   "source": [
    "# Compute a 95% confidence interval for the generalization error \n",
    "*using scipy.stats.t.interval():*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "ngWpgPrE3NaS"
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "6RFaMou83WBY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47467.12510437, 51666.58709056])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE HERE\n",
    "\n",
    "confidence = 0.95\n",
    "squared_errors = (best_predictions - y_test) ** 2\n",
    "np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,\n",
    "loc = squared_errors.mean(), scale = stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTsy6N8Uytpo"
   },
   "source": [
    "# Great Job!\n",
    "# #shAI_Club"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
